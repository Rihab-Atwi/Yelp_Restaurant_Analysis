{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose\n",
    "\n",
    "This Jupyter Notebook is created with the following objectives:\n",
    "\n",
    "## Objective 1: Filtering Non-English Reviews\n",
    "\n",
    "The first goal of this notebook is to filter out non-English reviews from a dataset. Non-English reviews can introduce noise when performing text analysis, and it's important to focus on English-language data for this analysis.\n",
    "\n",
    "## Objective 2: Applying Topic Modeling\n",
    "\n",
    "The second objective of this notebook is to apply topic modeling techniques to the filtered English-language reviews. Topic modeling helps in uncovering hidden themes or topics within textual data, which can be valuable for various applications such as sentiment analysis, content categorization, and understanding customer feedback.\n",
    "\n",
    "By the end of this notebook, we aim to have a clean dataset of English reviews and a set of identified topics that can be used for further analysis and insights.\n",
    "\n",
    "Let's proceed with the tasks to achieve these objectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The main reason I am performing these two steps here and not in the ETL process is the time it takes for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_review = pd.read_csv('C:\\\\Users\\\\User\\\\Desktop\\\\Final Project\\\\CSV_files\\\\mixed_review.csv')\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df_review = df_review.loc[df_review['text'].apply(is_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review.to_csv('english_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2: Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\Desktop\\\\Final Project\\\\english_review.csv')\n",
    "\n",
    "# Text Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Create an empty list to store the topics for each review\n",
    "all_topics = []\n",
    "\n",
    "for review in df['text']:\n",
    "    # Tokenize and preprocess the review text\n",
    "    tokenized_review = word_tokenize(review.lower())\n",
    "    filtered_review = [word for word in tokenized_review if word not in stop_words and word.isalpha()]\n",
    "\n",
    "    # Topic Modeling using Latent Dirichlet Allocation (same as in your original code)\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # The input for fit_transform should be a list of strings, not a list of lists\n",
    "    tfidf_review = tfidf_vectorizer.fit_transform([\" \".join(filtered_review)])\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=2, random_state=42)  # You can adjust the number of topics\n",
    "    lda.fit(tfidf_review)\n",
    "\n",
    "    # Get the top words for the topic\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    topic = lda.components_[0] if lda.components_[0].sum() > lda.components_[1].sum() else lda.components_[1]\n",
    "    top_words_idx = topic.argsort()[-5:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "\n",
    "    # Append the top words to the 'all_topics' list\n",
    "    all_topics.append(\", \".join(top_words))\n",
    "\n",
    "# Add a new column 'topic' to the DataFrame and store the topics\n",
    "df['topic'] = all_topics\n",
    "\n",
    "# Save the DataFrame to a new CSV file with the added 'topic' column\n",
    "df.to_csv('english_topic_review.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\Desktop\\\\Final Project\\\\english_topic_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>usually, long, pleasant, waiting, want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>VJxlBnJmCDIy8DFG0kjSow</td>\n",
       "      <td>Iaee7y6zdSB3B-kRCo4z1w</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is the second time we tried turning point...</td>\n",
       "      <td>2017-05-13 17:06:55</td>\n",
       "      <td>time, wait, chopped, long, food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>S6pQZQocMB1WHMjTRbt77A</td>\n",
       "      <td>ejFxLGqQcWNLdNByJlIhnQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The place is cute and the staff was very frien...</td>\n",
       "      <td>2017-08-08 00:58:18</td>\n",
       "      <td>nice, brunch, place, away, avocado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>WqgTKVqWVHDHjnjEsBvUgg</td>\n",
       "      <td>f7xa0p_1V9lx53iIGN5Sug</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We came on a Saturday morning after waiting a ...</td>\n",
       "      <td>2017-11-19 02:20:23</td>\n",
       "      <td>came, server, away, got, right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>M0wzFFb7pefOPcxeRVbLag</td>\n",
       "      <td>dCooFVCk8M1nVaQqcfTL3Q</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mediocre at best. The decor is very nice, and ...</td>\n",
       "      <td>2017-09-09 17:49:47</td>\n",
       "      <td>food, one, us, time, star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id               review_id                 user_id  \\\n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA   \n",
       "1  XQfwVwDr-v0ZS3_CbbE5Xw  VJxlBnJmCDIy8DFG0kjSow  Iaee7y6zdSB3B-kRCo4z1w   \n",
       "2  XQfwVwDr-v0ZS3_CbbE5Xw  S6pQZQocMB1WHMjTRbt77A  ejFxLGqQcWNLdNByJlIhnQ   \n",
       "3  XQfwVwDr-v0ZS3_CbbE5Xw  WqgTKVqWVHDHjnjEsBvUgg  f7xa0p_1V9lx53iIGN5Sug   \n",
       "4  XQfwVwDr-v0ZS3_CbbE5Xw  M0wzFFb7pefOPcxeRVbLag  dCooFVCk8M1nVaQqcfTL3Q   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      2       0      0     0   \n",
       "2      4       2      0     1   \n",
       "3      3       0      0     0   \n",
       "4      2       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  This is the second time we tried turning point...  2017-05-13 17:06:55   \n",
       "2  The place is cute and the staff was very frien...  2017-08-08 00:58:18   \n",
       "3  We came on a Saturday morning after waiting a ...  2017-11-19 02:20:23   \n",
       "4  Mediocre at best. The decor is very nice, and ...  2017-09-09 17:49:47   \n",
       "\n",
       "                                    topic  \n",
       "0  usually, long, pleasant, waiting, want  \n",
       "1         time, wait, chopped, long, food  \n",
       "2      nice, brunch, place, away, avocado  \n",
       "3          came, server, away, got, right  \n",
       "4               food, one, us, time, star  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_etl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
